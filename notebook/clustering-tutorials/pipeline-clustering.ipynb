{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import simplejson as json\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from loguru import logger\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from justatom.modeling.mask import ILanguageModel\n",
    "\n",
    "from justatom.configuring.prime import Config\n",
    "from justatom.running.cluster import IBTRunner, IHFWrapperBackend\n",
    "from justatom.modeling.prime import DocEmbedder\n",
    "from justatom.clustering.prime import IUMAPDimReducer\n",
    "from justatom.viewing.prime import PlotlyScatterChart\n",
    "\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_from_dataset(dataset_name_or_path, **props):\n",
    "    from justatom.storing.dataset import API as DatasetApi\n",
    "    import polars as pl\n",
    "\n",
    "    maybe_df_or_iter = DatasetApi.named(dataset_name_or_path).iterator(**props)\n",
    "    if isinstance(maybe_df_or_iter, pl.DataFrame):\n",
    "        pl_data = maybe_df_or_iter\n",
    "    else:\n",
    "        dataset = list(maybe_df_or_iter)\n",
    "        pl_data = pl.from_dicts(dataset)\n",
    "    return pl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_docs = source_from_dataset(Path(os.getcwd()) / \".data\" / \"polaroids.ai.data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sections = [\n",
    "    \"Гладиатор\",\n",
    "    \"451 градус по Фаренгейту\",\n",
    "    \"Гарри Поттер и Узник Азкабана\",\n",
    "    \"Гарри Поттер и философский камень\",\n",
    "    \"Цветы для Элджернона\",\n",
    "    \"Гарри Поттер и Дары Смерти\",\n",
    "    \"Ведьмак\",\n",
    "    \"Сойка-пересмешница\",\n",
    "    \"Голодные игры\",\n",
    "    \"Голодные игры: И вспыхнет пламя\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sub_docs = pl_docs.filter(pl.col(\"title\").is_in(sub_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-21 04:44:32.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mThere are S=[1530] / [4992] subset of documents selected for clustering\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"There are S=[{pl_sub_docs.shape[0]}] / [{pl_docs.shape[0]}] subset of documents selected for clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_col = \"content\"\n",
    "title_col = \"title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_titles = pl_sub_docs.select(title_col).unique().to_series().to_list()\n",
    "js_sub_docs = pl_sub_docs.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_docs = [di[content_col] for di in js_sub_docs]\n",
    "js_labels = [di[title_col] for di in js_sub_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_cuda_or_mps():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda:0\"\n",
    "    elif torch.has_mps:\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-21 04:44:52.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mUsing device mps\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = maybe_cuda_or_mps()\n",
    "logger.info(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"intfloat/multilingual-e5-base\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from justatom.processing.mask import IProcessor\n",
    "from justatom.processing.prime import INFERProcessor, TripletProcessor\n",
    "from justatom.processing import ITokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ITokenizer.from_pretrained(model_name_or_path)\n",
    "processor = INFERProcessor(\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=512,\n",
    "    content_field=content_col,\n",
    "    prefix=\"query:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-21 04:44:57.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mjustatom.modeling.mask\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m144\u001b[0m - \u001b[1mLoading from huggingface hub via \"intfloat/multilingual-e5-base\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lm_model = ILanguageModel.load(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = DocEmbedder(model=lm_model, processor=processor, device=device)\n",
    "backend_wrapper = IHFWrapperBackend(embedder, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_config = dict(\n",
    "    top_n_words=10,\n",
    "    n_gram_range=[1, 1],\n",
    "    min_topic_size=5,\n",
    "    calculate_probabilities=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_runner = IBTRunner(**clustering_config, model=backend_wrapper, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74386a8227c45f5ad97d89d73192dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing dataset:   0%|          | 0/383 [00:00<?, ? Dicts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7a4ed2e5944d91bce574c4e95f0534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 04:45:30,988 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12497d4fb0eb42f8a3ff3e1e4dfae773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing dataset:   0%|          | 0/48 [00:00<?, ? Dicts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3150d36319f644859942bf703ea40a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 04:45:56,502 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-21 04:45:56,503 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "2025-03-21 04:46:00,723 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-21 04:46:00,723 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-03-21 04:46:00,750 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-21 04:46:00,754 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-03-21 04:46:00,866 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "embeddings = list(chain.from_iterable(embedder.encode(js_docs, verbose=True, batch_size=4)))\n",
    "topics, probs = bt_runner.fit_transform(docs=js_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_config = dict(\n",
    "    n_components=2,\n",
    "    n_neighbors=3,\n",
    "    min_dist=0.1,\n",
    "    metric=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = IUMAPDimReducer(**umap_config)\n",
    "points = reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare2d(docs, topics, labels, reduced_embeddings):\n",
    "    assert reduced_embeddings.shape[1] == 2, f\"Embeddings shape mismatch Exptected 2D, got {embeddings.shape[1]}D\"\n",
    "    COLS_MAPPING=dict(\n",
    "        column_0=\"text\",\n",
    "        column_1=\"topic\",\n",
    "        column_2=\"label\",\n",
    "        column_3=\"x\",\n",
    "        column_4=\"y\"\n",
    "    )\n",
    "    pl_view = pl.from_dicts(zip(docs, topics, labels, reduced_embeddings[:, 0], reduced_embeddings[:, 1]))\n",
    "    pl_view = pl_view.rename(COLS_MAPPING)\n",
    "    return pl_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_view = prepare2d(docs=js_docs, topics=js_labels, labels=js_labels, reduced_embeddings=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from justatom.viewing.prime import PlotlyScatterChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = PlotlyScatterChart().view(pl_view, label_to_view=\"Вселенная\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "chart.write_image(f\"clustering_model=[e5]_dataset=[universe].png\", engine='kaleido', scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sub_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "justatom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
