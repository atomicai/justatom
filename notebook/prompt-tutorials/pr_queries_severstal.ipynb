{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import simplejson as json\n",
    "import polars as pl\n",
    "import json_repair\n",
    "from tqdm import tqdm\n",
    "from more_itertools import chunked\n",
    "from loguru import logger\n",
    "import asyncio as asio\n",
    "from justatom.tooling.stl import reuuid\n",
    "from justatom.storing.dataset import API as DatasetApi\n",
    "\n",
    "from justatom.etc.io import io_snapshot\n",
    "from justatom.tooling.reqs import openai_chat\n",
    "from justatom.tooling.coro import _limit_concurrency\n",
    "from justatom.running.igni import IGNIRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_from_dataset(dataset_name_or_path, **props):\n",
    "    from justatom.storing.dataset import API as DatasetApi\n",
    "    import polars as pl\n",
    "\n",
    "    maybe_df_or_iter = DatasetApi.named(dataset_name_or_path).iterator(**props)\n",
    "    if isinstance(maybe_df_or_iter, pl.DataFrame):\n",
    "        pl_data = maybe_df_or_iter\n",
    "    else:\n",
    "        dataset = list(maybe_df_or_iter)\n",
    "        pl_data = pl.from_dicts(dataset)\n",
    "    return pl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_or_path = Path.home() / \"IDataset\" / \"SEVERSTAL\" / \"SEVERSTAL_48_split_by_line.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_source_docs = source_from_dataset(dataset_name_or_path, sheet_name=\"Chunks\")\n",
    "pl_meta_docs = source_from_dataset(dataset_name_or_path, sheet_name=\"Documents\")\n",
    "pl_docs = pl_source_docs.join(pl_meta_docs, on=\"doc_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_source_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_col = \"chunk_text\"\n",
    "title_col = \"doc_name\"\n",
    "chunk_id_col = \"chunk_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"There are N=[{pl_docs.select('chunk_id').unique().shape[0]}] unique chunks\")\n",
    "logger.info(f\"There are D=[{pl_docs.select('doc_id').unique().shape[0]}] unique docs\")\n",
    "logger.info(f\"There L=[{pl_docs.select('doc_name').unique().shape[0]}] unique doc names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_for_props(d: dict, must_include_keys: list[str] = None) -> dict:\n",
    "    \"\"\"\n",
    "    :param d: Source doc\n",
    "    :param must_include_keys: List of keys to include\n",
    "    :return: New doc with only specified `must_include_keys`\n",
    "    \"\"\"\n",
    "    must_include_keys = d.keys() if must_include_keys is None else must_include_keys\n",
    "    return {key: d[key] for key in must_include_keys if key in d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def pipeline(\n",
    "    js_docs: list[dict],\n",
    "    pr_runner,\n",
    "    openai_model_name: str,\n",
    "    batch_size: int = 16,\n",
    "    coros_size: int = 2,\n",
    "    save_snapshot_every: int = 5,\n",
    "    snapshot_prefix: str = None,\n",
    "    snapshot_where: str = None,\n",
    "    timeout: int = 512,\n",
    "    must_include_keys: list[str] | None = None,\n",
    "    validate_json_response: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    We process `js_docs` by chunks where each chunk is of size `batch_size`.\n",
    "    Each chunk is processed asynchronously via parallel `coros_size` coroutines.\n",
    "\n",
    "    :param js_docs: documents to process\n",
    "    :param pr_runner: One of the instance `IPromptRunner` to create specific prompt\n",
    "    \"\"\"\n",
    "    pipes = []\n",
    "\n",
    "    for i, batch in tqdm(enumerate(chunked(js_docs, n=batch_size))):\n",
    "        _batch = batch\n",
    "        cur_result = await asio.gather(\n",
    "            *_limit_concurrency(\n",
    "                [\n",
    "                    openai_chat(\n",
    "                        pr_runner.prompt(**d),\n",
    "                        timeout=timeout,\n",
    "                        model=openai_model_name,\n",
    "                        props=wrapper_for_props(d, must_include_keys=must_include_keys),\n",
    "                    )\n",
    "                    for d in _batch\n",
    "                ],\n",
    "                concurrency=coros_size,\n",
    "            )\n",
    "        )\n",
    "        if not validate_json_response:\n",
    "            pipes.extend(cur_result)\n",
    "        else:\n",
    "            # NOTE: Order of execution is preserved.\n",
    "            js_answer_docs = [\n",
    "                pr_runner.finalize(\n",
    "                    raw_response=js_res[\"response\"], **wrapper_for_props(js_doc, must_include_keys=must_include_keys)\n",
    "                )\n",
    "                for js_doc, js_res in zip(batch, cur_result, strict=True)\n",
    "            ]\n",
    "            pipes.extend(js_answer_docs)\n",
    "\n",
    "        if (i + 1) % save_snapshot_every == 0:\n",
    "            io_snapshot(pipes, where=snapshot_where, snapshot_number=str(i + 1), snapshot_prefix=snapshot_prefix)\n",
    "    return pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_source_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_meta_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "Generate synthetic data from short questions that users can ask chatbots or customer support in Russian.\n",
    "\n",
    "The goal is to anticipate possible user questions, ensuring that they are clearly worded, appropriate to the context, and can be easily answered based on the context.\n",
    "\n",
    "# Stages of creating synthetic data\n",
    "1. Carefully study the document submitted to you and its context.\n",
    "2. Formulate brief questions related to the document and make sure that there are clear answers in the text.\n",
    "3. Make sure that each question is unique, and use different formulations to ensure diversity.\n",
    "4. Formulate answers strictly based on the content of the document.\n",
    "5. Write the question text in Russian only and make it suitable for chatbot or user support scenarios.\n",
    "\n",
    "(Optional: for real-world examples, more complex documents may be required, as well as various pairs of quality tests. Use PLACEHOLDERS for real texts and quality control.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from justatom.running.prompt import QUERIESPropmtRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model_name = \"gpt-4o-mini\"\n",
    "batch_size = 4\n",
    "coros_size = 2\n",
    "save_snapshot_every = 1\n",
    "must_include_keys = [\"chunk_id\", content_col, title_col]\n",
    "snapshot_prefix = \"SEVERSTAL|QUERIES\"\n",
    "snapshot_where = \"outputs\"\n",
    "source_language=\"Russian\"\n",
    "timeout  = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_runner = QUERIESPropmtRunner(\n",
    "    system_prompt=system_prompt.strip(),\n",
    "    source_language=source_language\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_docs = pl_docs.rename({content_col: \"content\", title_col: \"title\"})\n",
    "js_docs = pl_docs.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_runner._prepare(\n",
    "    **js_docs[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await pipeline(js_docs,openai_model_name=openai_model_name, pr_runner=pr_runner, batch_size=batch_size, coros_size=coros_size, save_snapshot_every=save_snapshot_every, must_include_keys=must_include_keys, snapshot_prefix=snapshot_prefix, snapshot_where=snapshot_where, timeout=timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "justatom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
